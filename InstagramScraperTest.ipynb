{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements:\n",
    "Scrape profiles and get:\n",
    "1. the number of posts\n",
    "2. the follower count\n",
    "3. number of likes on most liked post\n",
    "4. numbner of likes\n",
    "\n",
    "## Follow Up\n",
    "Save each profile in its own data frame with each row corresponding to a post <br>\n",
    "export as a excel file with each profile as a worksheet <br>\n",
    "find a way to edit so that the sheet includes some global account variables (ex. number of followers) outside the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from instascrape import Profile, scrape_posts, Post\n",
    "from selenium.webdriver import Chrome\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from openpyxl.workbook.child import INVALID_TITLE_REGEX\n",
    "from openpyxl import workbook\n",
    "import re\n",
    "from utils import check_valid_username, write_to_excel, get_top_post, create_post_df\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path.cwd()\n",
    "\n",
    "#mac\n",
    "#chrome_driver_path = cwd / 'chromedriver'\n",
    "\n",
    "#windows\n",
    "chrome_driver_path = cwd / 'chromedriver.exe'\n",
    "driver = Chrome(chrome_driver_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"user-agent\": \"Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Mobile Safari/537.36 Edg/87.0.664.57\",\n",
    "    \"cookie\": \"sessionid=7320119797%3AbistHHaSBGycwv%3A2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"Social_Media_Study_Handles.csv\")\n",
    "users = users.reindex(columns=[*users.columns, 'follower_count', 'number_of_posts'])\n",
    "\n",
    "#Specifying datatype for each columns\n",
    "users['School'] = users['School'].astype(object)\n",
    "users['IG Username'] = users['IG Username'].astype(object)\n",
    "users['follower_count'] = users['follower_count'].astype('Int64')\n",
    "users['number_of_posts'] = users['number_of_posts'].astype('Int64')\n",
    "\n",
    "# users = users.reindex(columns=[*users.columns, 'follower_count', 'number_of_posts', 'top_post_likes', \n",
    "# 'top_post_date_posted', 'top_post_url', 'first_post_likes', 'first_post_date_posted', 'first_post_url'])\n",
    "# This code is no longer userful since we are storing each account's posts in its own dataframe\n",
    "# users['top_post_likes'] = users['top_post_likes'].astype('Int64')\n",
    "# users['top_post_date_posted'] = users['top_post_date_posted'].astype('datetime64[ns]')\n",
    "# users['top_post_url'] = users['top_post_url'].astype(object)\n",
    "# users['first_post_likes'] = users['first_post_likes'].astype('Int64')\n",
    "# users['first_post_date_posted'] = users['first_post_date_posted'].astype('datetime64[ns]')\n",
    "# users['first_post_url'] = users['first_post_url'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "willseyeresidents\n",
      "33\n",
      "0: CDABF2hhEhP - 2020-07-23 17:49:11\n",
      "1: CC6_LwDhnTu - 2020-07-21 18:56:19\n",
      "2: CC4Kk8ZBGIc - 2020-07-20 16:38:09\n",
      "3: CCtc94uh_SW - 2020-07-16 12:47:12\n",
      "4: CCqrp49B5j1 - 2020-07-15 10:57:49\n",
      "5: CCjOYsGBwWO - 2020-07-12 13:27:23\n",
      "6: CCecas4hdY- - 2020-07-10 16:53:47\n",
      "7: CCHSdAehmf7 - 2020-07-01 17:04:11\n",
      "8: CB3xPaehw43 - 2020-06-25 16:25:22\n",
      "9: CBy5lzbBlq8 - 2020-06-23 19:02:08\n",
      "10: CBwQp8qhq3y - 2020-06-22 18:25:57\n",
      "11: CBtTXidBM4k - 2020-06-21 14:51:56\n",
      "12: CBqW91ohOfD - 2020-06-20 11:25:39\n",
      "13: CBoCRLXhQex - 2020-06-19 13:46:18\n",
      "14: CBlvolqAn4t - 2020-06-18 16:25:00\n",
      "15: CBjLzmHBJxE - 2020-06-17 16:33:27\n",
      "16: CANgGIPAQc0 - 2020-05-15 09:56:03\n",
      "17: CALFcpLAZq1 - 2020-05-14 11:24:43\n",
      "18: B_lFRQnBz3j - 2020-04-29 17:12:01\n",
      "19: B-sAg1yhXLQ - 2020-04-07 13:13:45\n",
      "20: B9Z5wFmBtvD - 2020-03-06 14:56:56\n",
      "21: B9HGomcBRkn - 2020-02-28 07:43:57\n",
      "22: B8nbgg2hDsc - 2020-02-16 00:30:39\n",
      "23: B7yyPaVB9wF - 2020-01-26 13:49:32\n",
      "24: B6UcX8CB3J_ - 2019-12-20 22:29:51\n",
      "25: B6TRZBrBHoW - 2019-12-20 11:34:38\n",
      "26: B5l3vIoBB4d - 2019-12-02 20:24:39\n",
      "27: B44xDRpB7iT - 2019-11-15 08:00:24\n",
      "28: B4i_dbXgK0u - 2019-11-06 21:03:01\n",
      "29: B4SmCO2g2C- - 2019-10-31 13:13:00\n",
      "30: B4IODOiA1lR - 2019-10-27 12:31:01\n",
      "31: B4Bb3OsAwPA - 2019-10-24 21:17:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/121 [05:56<11:52:12, 356.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: B4BZYIpAuYT - 2019-10-24 20:55:18\n",
      "bascompalmereye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/121 [06:30<5:30:59, 166.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "Bascom Palmer/University of Miami with username bascompalmereye has 237 posts, more than 200\n",
      "wilmereyeresidents\n",
      "34\n",
      "0: CVYQ03DrANh - 2021-10-23 13:13:33\n",
      "1: CU-eULLAyeZ - 2021-10-13 12:51:10\n",
      "2: CUKkD_-AGmc - 2021-09-23 09:00:53\n",
      "3: CTLCjN9rd5C - 2021-08-29 16:55:53\n",
      "4: CRwRrpghB4P - 2021-07-25 10:57:13\n",
      "5: CRIGjk4B2bf - 2021-07-09 20:30:23\n",
      "6: CRDNMZyhTKq - 2021-07-07 22:52:11\n",
      "7: CQjuxxIB98Y - 2021-06-25 17:29:57\n",
      "8: CMtBiTAhjET - 2021-03-21 22:01:27\n",
      "9: CKzaswbhAF7 - 2021-02-02 15:33:59\n",
      "10: CKJ7EzWh1yB - 2021-01-17 12:48:47\n",
      "11: CJjWki4hcnY - 2021-01-02 13:18:40\n",
      "12: CJKFwOuBfrA - 2020-12-23 17:50:42\n",
      "13: CI7S8ulBBXg - 2020-12-17 23:57:24\n",
      "14: CHHOF0HBjtU - 2020-11-02 22:03:02\n",
      "15: CEK--gvn7tR - 2020-08-21 20:33:45\n",
      "16: CEE7Gownxu_ - 2020-08-19 12:04:28\n",
      "17: CD0FBcwh8Jk - 2020-08-12 23:04:03\n",
      "18: CDNY5mJhJgz - 2020-07-28 22:27:21\n",
      "19: CCsEnnzBMPi - 2020-07-15 23:55:12\n",
      "20: CCfNRLEhLAi - 2020-07-11 00:00:39\n",
      "21: CCFTbxKBA5w - 2020-06-30 22:34:17\n",
      "22: CCAPSKrhGBC - 2020-06-28 23:21:49\n",
      "23: CB15aM6Hy3F - 2020-06-24 22:58:16\n",
      "24: CBjyUrkHqyH - 2020-06-17 22:10:01\n",
      "25: CBZUk-pHq_k - 2020-06-13 20:37:41\n",
      "26: CBPJMHaHIJW - 2020-06-09 21:45:46\n",
      "27: CBE89dhnk9P - 2020-06-05 22:46:30\n",
      "28: CA5jWuUHt5J - 2020-06-01 12:31:07\n",
      "29: CAvFmHBHkvT - 2020-05-28 10:58:40\n",
      "30: CAeMdz7Hmzu - 2020-05-21 21:31:37\n",
      "31: CAT5lo6g7D6 - 2020-05-17 21:34:15\n",
      "32: CAKADfKAClA - 2020-05-14 01:18:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/121 [12:34<8:25:08, 256.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33: CAJHZJ-AtfL - 2020-05-13 17:03:14\n",
      "uiowaeye\n",
      "131\n",
      "0: CVGjF6MLdlJ - 2021-10-16 16:06:50\n",
      "1: CU5gfRpLtyq - 2021-10-11 14:33:57\n",
      "2: CUz3DYRgbI1 - 2021-10-09 09:55:41\n",
      "3: CSFgrMYrfZY - 2021-08-02 16:52:17\n",
      "4: CR4eaSih6Rh - 2021-07-28 15:22:22\n",
      "5: CRZ9tDLBZO4 - 2021-07-16 18:59:22\n",
      "6: CNDcat-hs1J - 2021-03-30 14:59:38\n",
      "7: CMVMAzah-wd - 2021-03-12 14:51:13\n",
      "8: CLxXNG7h8TX - 2021-02-26 16:57:51\n",
      "9: CLxWUtIhCmI - 2021-02-26 16:48:39\n",
      "10: CLCioVhhEos - 2021-02-08 12:31:53\n",
      "11: CKwbZApBXJp - 2021-02-01 11:42:18\n",
      "12: CKSH8vMhObS - 2021-01-20 17:15:12\n",
      "13: CJeV2zyBa35 - 2020-12-31 14:36:13\n",
      "14: CJEFs4ahll6 - 2020-12-21 09:54:48\n",
      "15: CIZZd9ZhfZC - 2020-12-04 20:00:11\n",
      "16: CIHJ_1tBmqf - 2020-11-27 17:58:40\n",
      "17: CH1Wo83BDSc - 2020-11-20 20:02:48\n",
      "18: CHjUSibhiWR - 2020-11-13 19:55:56\n",
      "19: CHQrqnvBzA5 - 2020-11-06 14:14:38\n",
      "20: CHCF1n1hDTh - 2020-10-31 23:14:43\n",
      "21: CG0psvnhHze - 2020-10-26 17:58:43\n",
      "22: CGs_jM6BeuV - 2020-10-23 18:35:44\n",
      "23: CGbEc9Ohm1b - 2020-10-16 19:32:14\n",
      "24: CGIXPQEBYIL - 2020-10-09 13:10:49\n",
      "25: CF2apBbhYaU - 2020-10-02 13:54:13\n",
      "26: CFkVN7Uh-HP - 2020-09-25 13:20:30\n",
      "27: CFSBqmqhuPa - 2020-09-18 10:43:19\n",
      "28: CE_ykgChthF - 2020-09-11 08:45:05\n"
     ]
    }
   ],
   "source": [
    "#test purposes\n",
    "# users = users.head(5).append(users.iloc[89])\n",
    "\n",
    "#List of dataframes representing the posts of each user\n",
    "users_df = []\n",
    "\n",
    "#indicies of all users with more than 200 posts\n",
    "index_greater_200 = []\n",
    "\n",
    "#indicies of all users with less than 200 posts\n",
    "index_200_or_less = []\n",
    "\n",
    "for i in tqdm(range(0, len(users))):\n",
    "    if (not pd.isnull(users.iloc[i]['IG Username'])):\n",
    "        #Scrape the profile\n",
    "        print(users.iloc[i]['IG Username'])\n",
    "        profile = Profile(users.iloc[i]['IG Username'])\n",
    "        profile.scrape(headers=headers)\n",
    "\n",
    "        #Adding profile datapoints to dataframe\n",
    "        users.at[i, 'follower_count'] = profile.followers\n",
    "        users.at[i, 'number_of_posts'] = profile.posts\n",
    "\n",
    "        #Scraping Posts\n",
    "\n",
    "        posts = profile.get_posts(webdriver=driver)\n",
    "        print(len(posts))\n",
    "\n",
    "        #account has more than 200 posts\n",
    "        if (len(posts) > 200):\n",
    "            print(\"{} with username {} has {} posts, more than 200\".format(users.iloc[i]['School'], users.iloc[i]['IG Username'], len(posts)))\n",
    "            index_greater_200.append(i)\n",
    "        \n",
    "        else:\n",
    "            index_200_or_less.append(i)\n",
    "            try:\n",
    "                scraped_posts, unscraped = scrape_posts(posts, webdriver=driver, silent=False, headers=headers, pause=10)\n",
    "                \n",
    "                #Appending dataframe from account to each \n",
    "                users_df.append(create_post_df(scraped_posts))\n",
    "\n",
    "            except Exception as inst:\n",
    "                print(\"an error has occured on {}\".format(users.iloc[i]['IG Username']))\n",
    "                print(inst)\n",
    "                users_df.append(create_post_df([]))\n",
    "        \n",
    "    \n",
    "    # if no username, we're just going to add an empty dataframe\n",
    "    else:\n",
    "        users_df.append(create_post_df([]))\n",
    "\n",
    "    #Writing test dataframes to pickle object for easier debugging in the future\n",
    "    if (i % 10 == 0 and i != 0):\n",
    "        with open('test_dataframes_{}-{}.obj'.format(i-10, i), 'wb') as f:\n",
    "            pickle.dump((users_df, users), f)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #old code from just getting top and first posts\n",
    "        # top_post = get_top_post(scraped_posts)\n",
    "\n",
    "        # #Post are scraped from most recent to oldest, therefore, the earliest post will be the last one scraped in theory\n",
    "        # first_post = scraped_posts[-1]\n",
    "\n",
    "        # users.at[i, 'top_post_likes'] = top_post.likes\n",
    "        # users.at[i, 'top_post_date_posted'] = datetime.fromtimestamp(top_post.timestamp)\n",
    "        # users.at[i, 'top_post_url'] = \"instagram.com/p/{}\".format(top_post.shortcode)\n",
    "        # users.at[i, 'first_post_likes'] = first_post.likes\n",
    "        # users.at[i, 'first_post_date_posted'] = datetime.fromtimestamp(first_post.timestamp)\n",
    "        # users.at[i, 'first_post_url'] = \"instagram.com/p/{}\".format(first_post.shortcode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "len() takes exactly one argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10412/120729556.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwrite_to_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Albert\\Desktop\\InstagramScraper\\utils.py\u001b[0m in \u001b[0;36mwrite_to_excel\u001b[1;34m(user_post_dfs, users_df)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_post_dfs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0musers_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         raise ValueError(\"length of the posts dataframes and user dataframes are mismatched, there are {} posts dataframes and {} rows in the user dataframe\".format(\n\u001b[1;32m---> 71\u001b[1;33m             len(user_post_dfs), len(users_df.shape[0])))\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'User Data.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'openpyxl'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: len() takes exactly one argument (2 given)"
     ]
    }
   ],
   "source": [
    "write_to_excel(users_df, users.iloc[index_200_or_less])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing test dataframes to pickle object for easier debugging in the future\n",
    "with open('test_dataframes.obj', 'wb') as f:\n",
    "    pickle.dump((users_df, users), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_dataframes.obj', 'rb') as f:\n",
    "    loaded = pickle.load(f)\n",
    "\n",
    "users_df = loaded[0]\n",
    "users = loaded[1]\n",
    "users = users.reset_index()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "58e5a1f2200c9da4fe52d7508e5222fc267990c2fd40a29173e8fd4c8076db49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('instagramScraper': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
